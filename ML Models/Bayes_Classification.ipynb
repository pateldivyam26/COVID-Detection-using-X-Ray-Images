{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_SHAPE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_read(paths):\n",
    "    all_images = []\n",
    "    for path in paths:\n",
    "        for i in range(len(path)):\n",
    "            img = cv2.imread(path[i], 0)\n",
    "            normalized_img = cv2.resize(img, RESIZE_SHAPE)\n",
    "            all_images.append(normalized_img.flatten())\n",
    "    return np.array(all_images)\n",
    "\n",
    "def show_img(img):\n",
    "    return plt.imshow(np.reshape(img, RESIZE_SHAPE), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_test, y_pred):\n",
    "    print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"Recall Score: \", recall_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\train\\COVID\\\\*\")\n",
    "test_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\test\\COVID\\\\*\")\n",
    "val_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\val\\COVID\\\\*\")\n",
    "\n",
    "train_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\train\\\\Non-COVID\\\\*\")\n",
    "test_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\test\\\\Non-COVID\\\\*\")\n",
    "val_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\val\\\\Non-COVID\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_w = normalized_read([train_covid, train_non_covid])\n",
    "val_dataset_w = normalized_read([val_covid, val_non_covid])\n",
    "test_dataset_w = normalized_read([test_covid, test_non_covid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.append(np.ones(len(train_covid)), np.zeros(len(train_non_covid)))\n",
    "val_labels = np.append(np.ones(len(val_covid)), np.zeros(len(val_non_covid)))\n",
    "test_labels = np.append(np.ones(len(test_covid)), np.zeros(len(test_non_covid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame(train_dataset_w)\n",
    "train_dataset[\"label\"] = train_labels\n",
    "val_dataset = pd.DataFrame(val_dataset_w)\n",
    "val_dataset[\"label\"] = val_labels\n",
    "test_dataset = pd.DataFrame(test_dataset_w)\n",
    "test_dataset[\"label\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "test_dataset = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset[:, :-1]\n",
    "y_train = train_dataset[:, -1]\n",
    "\n",
    "X_val = val_dataset[:, :-1]\n",
    "y_val = val_dataset[:, -1]\n",
    "\n",
    "X_test = test_dataset[:, :-1]\n",
    "y_test = test_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bayes Classification Model Without PCA/LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1.785388708114624\n",
      "Accuracy Score:  0.691\n",
      "F1 Score:  0.6750788643533123\n",
      "Recall Score:  0.642\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.74      0.71       500\n",
      "         1.0       0.71      0.64      0.68       500\n",
      "\n",
      "    accuracy                           0.69      1000\n",
      "   macro avg       0.69      0.69      0.69      1000\n",
      "weighted avg       0.69      0.69      0.69      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "start = time.time()\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "nb_pred = nb_model.predict(X_val)\n",
    "results(y_val, nb_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bayes Classification Model With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_dataset_w)\n",
    "test_data = pd.DataFrame(test_dataset_w)\n",
    "val_data = pd.DataFrame(val_dataset_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.99)\n",
    "pca.fit(train_data)\n",
    "\n",
    "reduced_train_data = pca.transform(train_data)\n",
    "reduced_test_data = pca.transform(test_data)\n",
    "reduced_val_data = pca.transform(val_data)\n",
    "\n",
    "pca_train_data = pd.DataFrame(reduced_train_data)\n",
    "pca_test_data = pd.DataFrame(reduced_test_data)\n",
    "pca_val_data = pd.DataFrame(reduced_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.14632582664489746\n",
      "Accuracy Score:  0.612\n",
      "F1 Score:  0.6761268781302171\n",
      "Recall Score:  0.81\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      0.41      0.52       500\n",
      "         1.0       0.58      0.81      0.68       500\n",
      "\n",
      "    accuracy                           0.61      1000\n",
      "   macro avg       0.63      0.61      0.60      1000\n",
      "weighted avg       0.63      0.61      0.60      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "start = time.time()\n",
    "nb_model_pca = GaussianNB()\n",
    "nb_model_pca.fit(pca_train_data, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "nb_pred_pca = nb_model_pca.predict(pca_val_data)\n",
    "results(y_val, nb_pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Bayes Classification Model With LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=None)\n",
    "lda.fit(train_data, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtrain_data = lda.transform(train_data)\n",
    "rtest_data = lda.transform(test_data)\n",
    "rval_data = lda.transform(val_data)\n",
    "\n",
    "lda_train_data = pd.DataFrame(rtrain_data)\n",
    "lda_test_data = pd.DataFrame(rtest_data)\n",
    "lda_val_data = pd.DataFrame(rval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.0019676685333251953\n",
      "Accuracy Score:  0.759\n",
      "F1 Score:  0.756319514661274\n",
      "Recall Score:  0.748\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.77      0.76       500\n",
      "         1.0       0.76      0.75      0.76       500\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "start = time.time()\n",
    "nb_model_lda = GaussianNB()\n",
    "nb_model_lda.fit(lda_train_data, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "nb_pred_lda = nb_model_lda.predict(lda_val_data)\n",
    "results(y_val, nb_pred_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(nb_model, 'Bayes_Classification.pkl')    # Save the model as a pickle in a file"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e0580afa3568e9831e78fb07401b3217cb49abd6781e8c63feefa05b4cb53f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('prml_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
