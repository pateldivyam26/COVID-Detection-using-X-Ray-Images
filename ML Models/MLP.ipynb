{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Description and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE_SHAPE = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_read(paths):\n",
    "    all_images = []\n",
    "    for path in paths:\n",
    "        for i in range(len(path)):\n",
    "            img = cv2.imread(path[i], 0)\n",
    "            normalized_img = cv2.resize(img, RESIZE_SHAPE)\n",
    "            all_images.append(normalized_img.flatten())\n",
    "    return np.array(all_images)\n",
    "\n",
    "def show_img(img):\n",
    "    return plt.imshow(np.reshape(img, RESIZE_SHAPE), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_test, y_pred):\n",
    "    print(\"Accuracy Score: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"F1 Score: \", f1_score(y_test, y_pred))\n",
    "    print(\"Recall Score: \", recall_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\train\\COVID\\\\*\")\n",
    "test_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\test\\COVID\\\\*\")\n",
    "val_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\val\\COVID\\\\*\")\n",
    "\n",
    "train_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\train\\\\Non-COVID\\\\*\")\n",
    "test_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\test\\\\Non-COVID\\\\*\")\n",
    "val_non_covid  = glob.glob(\"D:\\YEAR 2\\SEMESTER 2\\PATTERN RECOGNITION & ML\\ML PROJECT\\Dataset Main\\\\val\\\\Non-COVID\\\\*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_w = normalized_read([train_covid, train_non_covid])\n",
    "val_dataset_w = normalized_read([val_covid, val_non_covid])\n",
    "test_dataset_w = normalized_read([test_covid, test_non_covid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.append(np.ones(len(train_covid)), np.zeros(len(train_non_covid)))\n",
    "val_labels = np.append(np.ones(len(val_covid)), np.zeros(len(val_non_covid)))\n",
    "test_labels = np.append(np.ones(len(test_covid)), np.zeros(len(test_non_covid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame(train_dataset_w)\n",
    "train_dataset[\"label\"] = train_labels\n",
    "val_dataset = pd.DataFrame(val_dataset_w)\n",
    "val_dataset[\"label\"] = val_labels\n",
    "test_dataset = pd.DataFrame(test_dataset_w)\n",
    "test_dataset[\"label\"] = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = np.array(train_dataset)\n",
    "val_dataset = np.array(val_dataset)\n",
    "test_dataset = np.array(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_dataset[:, :-1]\n",
    "y_train = train_dataset[:, -1]\n",
    "\n",
    "X_val = val_dataset[:, :-1]\n",
    "y_val = val_dataset[:, -1]\n",
    "\n",
    "X_test = test_dataset[:, :-1]\n",
    "y_test = test_dataset[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying MLPClassifier Without LDA/PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 186.59312653541565\n",
      "Accuracy Score:  0.654\n",
      "F1 Score:  0.49855072463768113\n",
      "Recall Score:  0.344\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.96      0.74       500\n",
      "         1.0       0.91      0.34      0.50       500\n",
      "\n",
      "    accuracy                           0.65      1000\n",
      "   macro avg       0.75      0.65      0.62      1000\n",
      "weighted avg       0.75      0.65      0.62      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "start = time.time()\n",
    "mlp_model = MLPClassifier()\n",
    "mlp_model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "mlp_pred = mlp_model.predict(X_val)\n",
    "results(y_val, mlp_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying MLPClassifier With PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(train_dataset_w)\n",
    "test_data = pd.DataFrame(test_dataset_w)\n",
    "val_data = pd.DataFrame(val_dataset_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components= 0.99)\n",
    "pca.fit(train_data)\n",
    "\n",
    "reduced_train_data = pca.transform(train_data)\n",
    "reduced_test_data = pca.transform(test_data)\n",
    "reduced_val_data = pca.transform(val_data)\n",
    "\n",
    "pca_train_data = pd.DataFrame(reduced_train_data)\n",
    "pca_test_data = pd.DataFrame(reduced_test_data)\n",
    "pca_val_data = pd.DataFrame(reduced_val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 355.60622358322144\n",
      "Accuracy Score:  0.815\n",
      "F1 Score:  0.8162859980139027\n",
      "Recall Score:  0.822\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.81      0.81       500\n",
      "         1.0       0.81      0.82      0.82       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model_pca = MLPClassifier()\n",
    "mlp_model_pca.fit(pca_train_data, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "mlp_pred_pca = mlp_model_pca.predict(pca_val_data)\n",
    "results(y_val, mlp_pred_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying MLPClassifier With LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda = LDA(n_components=None)\n",
    "lda.fit(train_data, y_train)\n",
    "\n",
    "rtrain_data = lda.transform(train_data)\n",
    "rtest_data = lda.transform(test_data)\n",
    "rval_data = lda.transform(val_data)\n",
    "\n",
    "lda_train_data = pd.DataFrame(rtrain_data)\n",
    "lda_test_data = pd.DataFrame(rtest_data)\n",
    "lda_val_data = pd.DataFrame(rval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 509.7986800670624\n",
      "Accuracy Score:  0.764\n",
      "F1 Score:  0.764\n",
      "Recall Score:  0.764\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.76      0.76       500\n",
      "         1.0       0.76      0.76      0.76       500\n",
      "\n",
      "    accuracy                           0.76      1000\n",
      "   macro avg       0.76      0.76      0.76      1000\n",
      "weighted avg       0.76      0.76      0.76      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlp_model_lda = MLPClassifier()\n",
    "mlp_model_lda.fit(lda_train_data, y_train)\n",
    "end = time.time()\n",
    "print(\"Training time: %s\" % str(end-start))\n",
    "mlp_pred_lda = mlp_model_lda.predict(lda_val_data)\n",
    "results(y_val, mlp_pred_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP.pkl']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(mlp_model, 'MLP.pkl')    # Save the model as a pickle in a file"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6e0580afa3568e9831e78fb07401b3217cb49abd6781e8c63feefa05b4cb53f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('prml_proj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
